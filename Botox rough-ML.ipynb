{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tropical-settle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duskb\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "C:\\Users\\duskb\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, confusion_matrix\n",
    "import scipy.stats\n",
    "import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\", font_scale=0.8, rc={\"lines.linewidth\": 1})\n",
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('botox database.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-rental",
   "metadata": {},
   "source": [
    "# Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Mirabegron'] = df['Mirabegron'].replace(['N', 'Y'], [0, 1])\n",
    "df['Anticholinergics'] = df['Anticholinergics'].replace(['N', 'Y'], [0, 1])\n",
    "df['DO'] = df['DO'].replace(['N', 'Y'], [0, 1])\n",
    "df['BOO'] = df['BOO'].replace(['N', 'Y'], [0, 1])\n",
    "df['Neuropathic'] = df['Neuropathic'].replace(['N', 'Y'], [0, 1])\n",
    "df['SUI'] = df['SUI'].replace(['N', 'Y'], [0, 1])\n",
    "df['UUI'] = df['UUI'].replace(['N', 'Y'], [0, 1])\n",
    "df['Incontinence surgery'] = df['Incontinence surgery'].replace(['N', 'Y'], [0, 1])\n",
    "df['Hysterectomy'] = df['Hysterectomy'].replace(['N', 'Y'], [0, 1])\n",
    "df['Previous bladder outflow surgery'] = df['Previous bladder outflow surgery'].replace(['N', 'Y'], [0, 1])\n",
    "df['PPI'] = df['PPI'].replace(['N', 'Y'], [0, 1])\n",
    "df['Middle lobe?'] = df['Middle lobe?'].replace(['N', 'Y'], [0, 1])\n",
    "df['CISC'] = df['CISC'].replace(['N', 'Y'], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-compatibility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log PVR'] = np.log10(df['PVR']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['PVR', 'log PVR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dose <100'] = [1 if x<=100 else 0 for x in df['Dose']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-earth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['Dose', 'Dose <100']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfF = df[df['Gender']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfM = df[df['Gender']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-threat",
   "metadata": {},
   "source": [
    "# Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Counts(df, var):\n",
    "    counts = df[var].value_counts()\n",
    "    percent = df[var].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "    return pd.DataFrame({'N': counts, '%': percent}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-philippines",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counts(df, \"Dose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Dose\", y=\"CISC\", data=df, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counts(dfF, \"CISC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counts(dfM, \"CISC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont=pd.crosstab(dfM['PPI'], dfM['CISC'])\n",
    "cont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-cholesterol",
   "metadata": {},
   "source": [
    "Of men without RARP, CISC rates were 68%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-female",
   "metadata": {},
   "source": [
    "# ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-junction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = df[['Age', 'Gender', 'DO', 'BOO','Neuropathic','SUI','UUI','PVR','Hysterectomy','PPI','Prostate size (ml)', 'Dose <100', 'Mirabegron', 'Anticholinergics']]\n",
    "y = df['CISC']\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-watch",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1)\n",
    "print(x_train)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalerX = StandardScaler().fit(x_train)\n",
    "x_train = scalerX.transform(x_train)\n",
    "x_test = scalerX.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.tensor(x,dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values,dtype=torch.float32)\n",
    "        self.length = self.x.shape[0]\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]  \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "trainset = dataset(x_train,y_train)\n",
    "testset = dataset(x_test,y_test)\n",
    "#DataLoader\n",
    "trainloader = DataLoader(trainset,batch_size=64,shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,input_shape):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,32)\n",
    "        self.fc2 = nn.Linear(32,64)\n",
    "        self.fc3 = nn.Linear(64,1)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "    def forward(self,x):\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "epochs = 600\n",
    "\n",
    "# Model , Optimizer, Loss\n",
    "model = Net(input_shape=x.shape[1])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "#forward loop\n",
    "train_losses, test_losses = [], []\n",
    "accur = []\n",
    "for i in range(epochs):\n",
    "    for j,(x_train,y_train) in enumerate(trainloader):\n",
    "    \n",
    "        #calculate output\n",
    "        output = model(x_train)\n",
    " \n",
    "        #calculate loss\n",
    "        running_loss = loss_fn(output,y_train.reshape(-1,1))\n",
    " \n",
    "        #accuracy\n",
    "        #predicted = model(torch.tensor(x,dtype=torch.float32))\n",
    "        #acc = (predicted.reshape(-1).detach().numpy().round() == y).mean() \n",
    "        \n",
    "        #backprop\n",
    "        optimizer.zero_grad()\n",
    "        running_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for j,(x_test,y_test) in enumerate(testloader):\n",
    "                output = model(x_test)\n",
    " \n",
    "                #calculate loss\n",
    "                test_loss = loss_fn(output,y_test.reshape(-1,1))\n",
    " \n",
    "                #accuracy\n",
    "                #predicted = model(torch.tensor(x_test,dtype=torch.float32))\n",
    "                #acc = (predicted.reshape(-1).detach().numpy().round() == y_test).mean() \n",
    "        \n",
    "    if i%50 == 0:\n",
    "        train_losses.append(running_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        #accur.append(acc)\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(i+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss))\n",
    "              #\"Test Accuracy: {:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the accuracy\n",
    "plt.plot(accur)\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "params = x_train[0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.forward(params)\n",
    "\n",
    "ps = torch.sigmoid(output)\n",
    "print(scalerX.inverse_transform(x_train[0]))\n",
    "print(ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
